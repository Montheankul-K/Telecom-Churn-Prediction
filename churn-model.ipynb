{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset \n",
    "dataset = './data/telecom-customer-churn.csv'\n",
    "popDataset = './data/telecom-zipcode-population.csv'\n",
    "dataframe = pd.read_csv(dataset)\n",
    "popDataframe = pd.read_csv(popDataset)\n",
    "dataset = dataframe.head(10)\n",
    "popDataset = popDataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null column\n",
    "naRowCount = dataframe.isnull().sum()\n",
    "popNaRowCount = popDataframe.isnull().sum()\n",
    "print(f\"NA row count of dataset : {naRowCount}\")\n",
    "print(f\"NA row count of population dataset : {popNaRowCount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean churn category and churn reason field by filling NaN values\n",
    "dataframe['Churn Category'].fillna('Not provided', inplace=True)\n",
    "dataframe['Churn Reason'].fillna('Not provided', inplace=True)\n",
    "\n",
    "# Clean offer field by filling NaN values\n",
    "dataframe['Offer'].fillna('None', inplace=True)\n",
    "\n",
    "# Clean fields that depend on phone service subscription with a conditional replace\n",
    "dataframe['Avg Monthly Long Distance Charges'] = dataframe.apply(lambda row: 0 if row['Phone Service'] == 'No' else row['Avg Monthly Long Distance Charges'], axis=1)\n",
    "dataframe['Multiple Lines'] = dataframe.apply(lambda row: 'No' if row['Phone Service'] == 'No' else row['Multiple Lines'],axis=1)\n",
    "\n",
    "# Clean fields that depend on internet service subscription with a conditional replace\n",
    "internetServiceCols = ['Internet Type', 'Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data']\n",
    "for col in internetServiceCols:\n",
    "    dataframe[col] = dataframe.apply(lambda row: 'No' if row['Internet Service'] == 'No' else row[col], axis=1)\n",
    "dataframe['Avg Monthly GB Download'] = dataframe.apply(lambda row: 0 if row['Internet Service'] == 'No' else row['Avg Monthly GB Download'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join datataset and population dataset \n",
    "fullDataframe = pd.merge(dataframe, popDataframe, on = 'Zip Code', how = 'left')\n",
    "fullDataframe = fullDataframe.drop(columns = ['Customer ID']) # Typically not use as a feature in ml model\n",
    "\n",
    "# Check missing value\n",
    "fullDataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Note\n",
    "# Split unseen dataset\n",
    "dataframeRow = fullDataframe.shape[0]\n",
    "unseenProportion = 0.2\n",
    "unseenSize = int(dataframeRow * unseenProportion)\n",
    "unseenDataset = fullDataframe.sample(n = unseenSize, random_state = 42)\n",
    "fullDataframe = fullDataframe.drop(unseenDataset.index)\n",
    "\n",
    "# Split feature and target of unseen dataset\n",
    "unseenFeature = unseenDataset.drop(columns = ['Customer Status'])\n",
    "unseenTarget = unseenDataset['Customer Status']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train test split\n",
    "# Defind feature and target\n",
    "feature = fullDataframe.drop(columns = ['Customer Status'])\n",
    "target = fullDataframe['Customer Status'] \n",
    "xFeature, yFeature, xTarget, yTarget = train_test_split(feature, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# Encode categorical features\n",
    "categoricalField = ['Gender', 'Married', 'City', 'Offer', 'Phone Service', 'Multiple Lines', 'Internet Service', 'Internet Type', 'Online Security', 'Online Backup', 'Device Protection Plan',\n",
    "'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music', 'Unlimited Data', 'Contract', 'Paperless Billing', 'Payment Method', 'Churn Category', 'Churn Reason']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "xFeature[categoricalField] = xFeature[categoricalField].apply(encoder.fit_transform)\n",
    "yFeature[categoricalField] = yFeature[categoricalField].apply(encoder.fit_transform)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numericalField = ['Age', 'Number of Dependents', 'Zip Code', 'Latitude', 'Longitude', 'Number of Referrals', 'Tenure in Months', 'Avg Monthly Long Distance Charges', 'Avg Monthly GB Download', \n",
    "'Monthly Charge', 'Total Charges', 'Total Refunds', 'Total Extra Data Charges', 'Total Long Distance Charges', 'Total Revenue', 'Population']\n",
    "scaler.fit(xFeature[numericalField])\n",
    "scaler.fit(yFeature[numericalField])\n",
    "xFeature[numericalField] = scaler.transform(xFeature[numericalField])\n",
    "yFeature[numericalField] = scaler.transform(yFeature[numericalField])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Note\n",
    "# Train random forest model \n",
    "# K-fold cross validation\n",
    "k = 5\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 42)\n",
    "bestModel = None\n",
    "bestScore = 0\n",
    "\n",
    "for trainIndex, valIndex in kf.split(feature):\n",
    "    featureTrain, featureVal = feature.iloc[trainIndex], feature.iloc[valIndex]\n",
    "    targetTrain, targetVal = target.iloc[trainIndex], target.iloc[valIndex]\n",
    "    \n",
    "    rfModel = RandomForestClassifier()\n",
    "    rfModel.fit(featureTrain, targetTrain)\n",
    "    \n",
    "    score = rfModel.score(featureVal, targetVal)\n",
    "    if score > bestScore:\n",
    "        bestScore = score\n",
    "        bestModel = rfModel\n",
    "print(f'Best score : {bestScore}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Note\n",
    "# Prediction \n",
    "unseenDataEncoded = pd.get_dummies(unseenFeature)\n",
    "unseenDataEncoded = unseenDataEncoded.reindex(columns=feature.columns, fill_value=0)\n",
    "prediction = bestModel.predict(unseenDataEncoded)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(unseenTarget, prediction)\n",
    "precision = precision_score(unseenTarget, prediction, average='weighted')\n",
    "recall = recall_score(unseenTarget, prediction, average='weighted')\n",
    "f1 = f1_score(unseenTarget, prediction, average='weighted')\n",
    "confMatrix = confusion_matrix(unseenTarget, prediction)\n",
    "print(f'Accuracy : {accuracy}\\n Precision : {precision} \\n Recall : {recall} \\n F1 score : {f1} \\n Confusion matrix : {confMatrix}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0\n",
      " Precision : 1.0 \n",
      " Recall : 1.0 \n",
      " F1 score : 1.0 \n",
      " Confusion matrix : [[ 551    0    0]\n",
      " [   0  153    0]\n",
      " [   0    0 1409]]\n"
     ]
    }
   ],
   "source": [
    "# Train model with random forest\n",
    "xFeatureEncoded = pd.get_dummies(xFeature)\n",
    "xFeature = xFeatureEncoded.reindex(columns=feature.columns, fill_value=0)\n",
    "rfModel = RandomForestClassifier()\n",
    "rfModel = rfModel.fit(xFeature,xTarget) \n",
    "\n",
    "# Prediction \n",
    "rfPrediction = rfModel.predict(yFeature)\n",
    "# Scoring\n",
    "accuracy = accuracy_score(yTarget, rfPrediction)\n",
    "precision = precision_score(yTarget, rfPrediction, average='weighted')\n",
    "recall = recall_score(yTarget, rfPrediction, average='weighted')\n",
    "f1 = f1_score(yTarget, rfPrediction, average='weighted')\n",
    "confMatrix = confusion_matrix(yTarget, rfPrediction)\n",
    "print(f'Accuracy : {accuracy}\\n Precision : {precision} \\n Recall : {recall} \\n F1 score : {f1} \\n Confusion matrix : {confMatrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9001419782300047\n",
      " Precision : 0.899063422653525 \n",
      " Recall : 0.9001419782300047 \n",
      " F1 score : 0.8961615133449948 \n",
      " Confusion matrix : [[ 430   21  100]\n",
      " [  15   90   48]\n",
      " [  15   12 1382]]\n"
     ]
    }
   ],
   "source": [
    "# Train model with random forest\n",
    "lrModel = LogisticRegression(solver='liblinear')\n",
    "lrModel = lrModel.fit(xFeature,xTarget)\n",
    "\n",
    "# Prediction \n",
    "lrPrediction = lrModel.predict(yFeature)\n",
    "# Scoring\n",
    "accuracy = accuracy_score(yTarget, lrPrediction)\n",
    "precision = precision_score(yTarget, lrPrediction, average='weighted')\n",
    "recall = recall_score(yTarget, lrPrediction, average='weighted')\n",
    "f1 = f1_score(yTarget, lrPrediction, average='weighted')\n",
    "confMatrix = confusion_matrix(yTarget, lrPrediction)\n",
    "print(f'Accuracy : {accuracy}\\n Precision : {precision} \\n Recall : {recall} \\n F1 score : {f1} \\n Confusion matrix : {confMatrix}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
